---
title: 'Exploring freMTPL2freq (French Motor Third-Party Liability Frequency datasete)'
author: "Kenji Kondo"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: kate
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(CASdatasets)
library(purrr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(assertthat)
library(aglm)
par(ps=8)
set.seed(2020)  # Set seed for reproducibility.
```


# What is the data?

## R help

> In the two datasets freMTPL2freq, freMTPL2sev, risk features are collected for 677,991 motor third-part liability policies (observed mostly on one year). In addition, we have claim numbers > by policy as well as the corresponding claim amounts. freMTPL2freq contains the risk features and the claim number while freMTPL2sev contains the claim amount and the corresponding policy ID.

## Format
* IDpol: The policy ID (used to link with the claims dataset).
* ClaimNb: Number of claims during the exposure period.
* Exposure: The period of exposure for a policy, in years.
* VehPower: The power of the car (ordered values).
* VehAge: The vehicle age, in years.
* DrivAge: The driver age, in years (in France, people can drive a car at 18).
* BonusMalus: Bonus/malus, between 50 and 350: <100 means bonus, >100 means malus in France.
* VehBrand: The car brand (unknown categories).
* VehGas: The car gas, Diesel or regular.
* Area: The density value of the city community where the car driver lives in: from "A" for rural area to "F" for urban centre.
* Density: The density of inhabitants (number of inhabitants per square-kilometer) of the city where the car driver lives in.
* Region: The policy region in France (based on the 1970-2015 classification).

We will use `ClaimNb` as a response variable, `log(Exposure)` as offset, and others as explanatory variables in this analysis.


# Read the data

## Original data

```{r}
data("freMTPL2freq")
xy <- freMTPL2freq  # rename as `freq`
head(xy, 5)
```


## Preprocessing

```{r}
xy <- xy[-1]  # Discard policy ID's we don't use.
xy$ClaimNb <- as.integer(xy$ClaimNb)  # Because it has `table` type by default.
xy$VehGas <- factor(xy$VehGas)  # Convert strings into factor values.
xy$Area <- ordered(xy$Area)  # Convert them into ordered factor values, because this variable has order as abovementioned.
xy$VehBrand <- factor(substr(xy$VehBrand, 1, 2))  # Cut brand names to the first 2 letters, to plot them neatly
xy$Region <- factor(substr(xy$Region, 1, 2))  # same as above
head(xy)
```

```{r}
x <- xy[-c(1:2)]
y <- xy$ClaimNb
off <- log(xy$Exposure)  # use log(Exposure) as offset
```


# Look over the data

## Size of the data

```{r}
dim(xy)
```


## Missing values

```{r}
colSums(is.na(xy))
```

Now it is ensured that there are no missing values.


## Distribution of the response variable

```{r}
table(y)
```

The response values seem to contain too large values as claim numbers in less than one year.
Because these values are possibly disturbing, so we truncate them to 4 as below (FYI, our treatment is same as that in https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3164764 ).

```{r}
y[y > 4] <- 4
table(y)
```


## Distributions of offset

```{r}
plot(density(off))
```

Note that some values of offset is greater than 0, which means `Exposure > 1 yr`.
It is ambiguous whther these values ara by some errors or not, but we decided to remain them unchanged because such excess exposures seem to have some correlation with y values as we can see in boxplots below.

```{r}
excess_exp <- exp(off[off > 0]) - 1  # excess exposures over than one year
yy <- y[off > 0]  # corresponding y values

ggplot(data.frame(yy, excess_exp), aes(x=as.factor(yy), y=excess_exp)) +
  geom_boxplot() +
  scale_y_log10() +
  theme_bw()
```


## Distributions of explanatory variables

### Quantitative variables

```{r}
x %>%  # drop target variable
  keep(is.numeric) %>%
  gather() %>%
  ggplot(aes(value)) +
    facet_wrap(~ key, scales="free") +
    geom_density()
```


### Qualitative variables

```{r}
# The lines below results a warning of "attributes are not identical across measure variables; they will be dropped.", but it's because we gather multiple factor columns with different set of levels and no problem.
xy %>%
  discard(is.numeric) %>%
  gather() %>%
  ggplot(aes(value)) +
    facet_wrap(~ key, scales="free") +
    geom_bar()
```


# Split the data into a train and test pair
```{r}
n <- nrow(xy)  # Sample size.
test.id <- sample(n, round(n/4))  # ID numbders for test data.

# a dataset for training
x_train <- x[-test.id,]
y_train <- y[-test.id]
off_train <- off[-test.id]

# a dataset for evaluation
x_test <- x[test.id,]
y_test <- y[test.id]
off_test <- off[test.id]
```


# AGLM with Poisson family

## Choose hyperparameters

AGLM use the elastic-net type penalty, and it has two hyperparameters $\alpha$ and $\lambda$.
In short, $\alpha$ is the elastic-net mixing parameter, with $0 \le \alpha \le 1$, and \lambda is the strongness of penalty.
If specific value of alpha and lambda is given, the penalty for a coefficient Î² is wirten as $\lambda \{(1-\alpha)/2||\beta||_2^2+\alpha||\beta||_1\}$.
Note that `alpha = 1` is the lasso penalty, and `alpha = 0` the ridge penalty.

We can choose these hyperparameters by cross-validation using `cva.aglm()`.
An R code for this purpose is as below, but commented out it because this process is slightly time-consuming.

```{r}
# cva.model <- cva.aglm(x_train,
#                        y_train,
#                        offset=off_train,
#                        family="poisson",
#                        nbin.max=40,  # Reduce number of bins for computational reason (default is 100).
#                        trace.it=TRUE)
# alpha.min <- cva.model@alpha.min
# lambda.min <- cva.model@lambda.min
# 
# cat("Chosen hyperparameters", "\n",
#    "alpha.min: ", alpha.min, "\n",
#    "lamda.min: ", lambda.min, "\n")
```

Instead, use precalculated values here.

```{r}
alpha.min <- 1
lambda.min <- 0.00005440846715217542766025726752587843293440528213977813720703125
```


## Fit a model to the train data

```{r}
model_path <- "./freMTPL2freq_aglm.rda"
if (file.exists(model_path)) {  # to save time at the 2nd run
  load(file=model_path)
} else {
  best_model <- aglm(x_train,
                   y_train,
                   offset=off_train,
                   family="poisson",
                   nbin.max=40,
                   lambda=lambda.min,
                   alpha=alpha.min,
                   trace.it=TRUE)
  save(best_model, file=model_path)
}
```


## Predict for the test data

```{r}
y_pred <- predict(best_model, newx=x_test, newoffset=off_test, type="response")
```


## Evaluate the prediction

### Compare to y_true

To see how nice the prediction is, we use boxplots of the predicted means(y_pred) against true values(y_true) as below.

```{r}
ggplot(data.frame(y_test, y_pred), aes(x=as.factor(y_test), y=y_pred)) +
  geom_boxplot() +
  scale_y_log10() +  # Use log scale because y_pred has positively-skewed distribution.
  theme_bw()
```

Notice that medians of y_pred and y_true seem positively correlated (the case where `y_true=4` is an exception), which indicates some natures of occuring are actually captured in this model.


### Calculate a numerical measure

Because it is difficult to understand how accurate our prediction only from boxplots (especially in poisson cases), we calculate test deviance as below.

```{r}
dev_test <- 2 * mean(ifelse(y_test == 0, y_pred, y_test * log(y_test / y_pred) - y_test + y_pred))
cat("Test deviance: ", dev_test, "\n")
```

The calculated deviance value can be used when comparing this model to other models.


### Understand the model

We can also understand the model visually using the `plot()` function.
It draws component curves (say, link values against specific values of explanatory variables) and residuals for the train data.
In this case, we use deviance residuals (defferent from the default working residuals), and make it draw only smoothed lines of residuals, in order to get clearer plots.

```{r}
plot(best_model, verbose=FALSE, ask=FALSE,
     resid="deviance", smooth_resid="smooth_only",
     add_rug=TRUE,
     layout=c(2, 3))
```






