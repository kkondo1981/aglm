---
title: 'Modeling vehicle insurance dataset with AGLM'
author: "Kenji Kondo"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: kate
---

```{r setup, include=FALSE}
library(knitr)
library(rmdformats)

## Global options
options(max.print="75")
opts_chunk$set(echo=TRUE,
               message=FALSE,
               warning=FALSE)
opts_knit$set(width=75)
par(ps=8)

set.seed(20210612)
```


# What is the data?

The 'dataCar' dataset in the 'insuranceData' package.

```
data Car
Description
This data set is based on one-year vehicle insurance policies taken out in 2004 or 2005. There are 67856 policies, of which 4624 (6.8
```

# Read the data

```{r}
library(insuranceData)
data(dataCar)
xy <- dataCar
xy <- xy[xy$claimcst0 > 0, ]

y <- xy$claimcst0
x <- xy[c("agecat", "gender", "area", "veh_body")]
x$agecat_x_gender <- x$agecat * as.integer(x$gender)
x$veh_body <- factor(substr(x$veh_body, 1, 3))

dim(xy)
```

```{r}
hist(y, breaks=50)
```
```{r}
head(x)
```

# GLM

At first, let us try modeling with simple GLM, as in a textbook by De Jong P., Heller G.Z. (2008).

```{r}
model <- glm(y ~ agecat + gender + area + veh_body + agecat_x_gender,
             data=cbind(y, x),
             family=Gamma(link="log"))

print(model)
cat("Deviance/DF: ", model$deviance / model$df.residual, "\n")
```

I got a slightly different result from them ("Deviance/DF" is 1.561 in their book but 1.565 above), but seems not so bad.


# AGLM

First we will try to emulate simple GLM fitted in the previous section.

```{r}
library(aglm)

model <- aglm(x, y,
              family=Gamma(link="log"),
              nbin.max=2,
              lambda=0)

cat(sprintf("Deviance: %.0f\n", deviance(model)))
```

I won't bore you with the technical details, but setting `nbin.max=2` and `lambda=0` gives an AGLM model which is identical to simple GLM.
You can see its deviance is equals to that of GLM, and quantitative variables effect linearly as below.


```{r}
plot(model,
     layout=c(2, 3),
     verbose=FALSE,
     ask=FALSE)
```

Next, I would like to focus on the `agecat` variable, so plot only the variable again, with `resid=TRUE`.
Note that some of the residuals are large, I will draw only the smoothed curve with `smooth_resid="smooth_only"`.

```{r}
plot(model,
     vars="agecat",
     resid=TRUE,
     smooth_resid="smooth_only",
     verbose=FALSE,
     ask=FALSE)
```

This plot seems to suggest non-linearity, so I would like to try fitting AGLM without `nbin.max=2` and with selecting appropriate `lambda`.
(Another option not tried here is to use O-dummies for modeling `agecat`.)

```{r}
model <- cv.aglm(x, y,
                 family=Gamma(link="log"))
s <- model@lambda.min

plot(model,
     s=s,
     vars="agecat",
     resid=TRUE,
     smooth_resid="smooth_only",
     verbose=FALSE,
     ask=FALSE)
```

Note that the deviance of this model is larger than that of simple GLM.
But anyway, we will check their generalization performance later, by another way.

```{r}
cat(sprintf("Deviance: %.0f\n", deviance(model, s=s)))
```

Before leaving this section, I would like to examine searching $\alpha$ with `cva.aglm()` as below.
I recommend that you consider setting `parallel.alpha=TRUE` or reducing `nfolds` when using `cva.aglm()`, because it's somewhat time-consuming.

```{r}
library(doParallel) # for parallelization of `glmnet()`
library(parallel) # for `detectCores()`

registerDoParallel(detectCores())
model <- cva.aglm(x, y,
                  family=Gamma(link="log"),
                  parallel.alpha=TRUE)
stopImplicitCluster()

model <- model@models_list[[model@alpha.min.index]]
s <- model@lambda.min

plot(model,
     s=s,
     vars="agecat",
     resid=TRUE,
     smooth_resid="smooth_only",
     verbose=FALSE,
     ask=FALSE)
```

```{r}
cat(sprintf("Deviance: %.0f\n", deviance(model, s=s)))
```


# Cross-validation

Now we can see cross-validation errors to check generalization performances of model.
We would like to fit all the models again in order to use same folds for all.

```{r}
# GLM identical
cv1 <- cv.aglm(x, y,
               family=Gamma(link="log"),
               nbin.max=2,
               lambda=c(0, 1), # to avoid single-lambda error
               keep=TRUE)  # to remember foldid


# fixed alpha=1
cv2 <- cv.aglm(x, y,
               family=Gamma(link="log"),
               foldid=cv1@foldid)


# best alpha
registerDoParallel(detectCores())
cv3 <- cva.aglm(x, y,
                family=Gamma(link="log"),
                foldid=cv1@foldid,
                parallel.alpha=TRUE)
stopImplicitCluster()

cv3 <- cv3@models_list[[cv3@alpha.min.index]]
```

Now we can see the mean cross-validation errors for all the models as below.
Note that 'error' means deviance for folds not used to fit and devided by sample sizes.

```{r}
outf <- function(name, x) cat(sprintf("%s: %.5f\n", name, x))
outf("glm             ", cv1@cvm[match(0, cv1@lambda)])
outf("aglm(alpha=1)   ", cv2@cvm[match(cv2@lambda.min, cv2@lambda)])
outf("aglm(best alpha)", cv3@cvm[match(cv3@lambda.min, cv3@lambda)])
```

Judging from this metric, the last model is the best.
From the following plots, the difference seems to come from how to handle `agecat` and `agecat_x_gender`.

```{r}
s <- cv2@lambda.min
plot(cv2,
     s=s,
     layout=c(2, 3),
     resid=TRUE,
     smooth_resid="smooth_only",
     verbose=FALSE,
     ask=FALSE)
```


```{r}
s <- cv3@lambda.min
plot(cv3,
     s=s,
     layout=c(2, 3),
     resid=TRUE,
     smooth_resid="smooth_only",
     verbose=FALSE,
     ask=FALSE)
```


# References
* De Jong P., Heller G.Z. (2008), Generalized linear models for insurance data, Cambridge University Press
