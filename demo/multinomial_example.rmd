---
title: 'Multinomial regression with AGLM'
author: "Kenji Kondo"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: kate
---

```{r setup, include=FALSE}
library(knitr)
library(rmdformats)

## Global options
options(max.print="75")
opts_chunk$set(echo=TRUE,
               message=FALSE,
               warning=FALSE)
opts_knit$set(width=75)
par(ps=8)

set.seed(20210619)
```


# What is the data?

We will use the `MultinomialExample` dataset of `glmnet`.
It is a simulated dataset, used in [glmnet example](https://glmnet.stanford.edu/articles/glmnet.html#multinomial-regression-family-multinomial-).

# Read the data

```{r}
library(glmnet)
data(MultinomialExample)

x <- as.data.frame(x)

print(dim(x))
```

```{r}
table(y)
```

```{r}
head(x)
```


# Fitting simple GLM identical (as in 'data_car.rmd')

```{r}
library(doParallel) # for parallelization of `glmnet()`
library(parallel) # for `detectCores()`
library(aglm)

registerDoParallel(detectCores())

tm <- system.time(cv1 <- cva.aglm(x, y,
                                  family="multinomial",
                                  nbin.max=2,
                                  keep=TRUE,  # to record `foldid` to use later
                                  parallel.alpha=TRUE))

stopImplicitCluster()

print(tm)
```

```{r}
cat(sprintf("best alpha: %.5f\n", cv1@alpha.min))
cv1 <- cv1@models_list[[cv1@alpha.min.index]]

cat(sprintf("best lambda: %.5f\n", cv1@lambda.min))
s <- cv1@lambda.min
plot(cv1,
     s=s,
     #resid=TRUE,
     #smooth_resid="smooth_only",
     layout=c(3, 5),
     verbose=FALSE,
     ask=FALSE)
```


# Fitting AGLM

```{r}
registerDoParallel(detectCores())

tm <- system.time(cv2 <- cva.aglm(x, y,
                                  family="multinomial",
                                  foldid=cv1@foldid,
                                  parallel.alpha=TRUE))

stopImplicitCluster()

print(tm)
```

```{r}
cat(sprintf("best alpha: %.5f\n", cv2@alpha.min))
cv2 <- cv2@models_list[[cv2@alpha.min.index]]

cat(sprintf("best lambda: %.5f\n", cv2@lambda.min))
s <- cv2@lambda.min
plot(cv2,
     s=s,
     #resid=TRUE,
     #smooth_resid="smooth_only",
     layout=c(3, 5),
     verbose=FALSE,
     ask=FALSE)
```


# Cross-validation errors (mean deviance per sample)

```{r}
outf <- function(name, x) cat(sprintf("%s: %.5f\n", name, x))
outf("simple GLM with CV ", cv1@cvm[match(cv1@lambda.min, cv1@lambda)])
outf("AGLM with CV       ", cv2@cvm[match(cv2@lambda.min, cv2@lambda)])
```

The results show that the simpler model is better.
Since `MultinomialExample` is artificial data, it is possible that the true model is actually simple, or that the results may change when the sample size is increased.
